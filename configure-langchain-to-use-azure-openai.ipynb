{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install the latest packages `langchain` and `langchain-openai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set the environment variables, which should include `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_API_VERSION`, and `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of AzureChatOpenAI called `model`, and pass the list of messages to the invoke method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# create a llm\n",
    "model = AzureChatOpenAI(\n",
    "  openai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "  azure_deployment = os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"]\n",
    ")\n",
    "\n",
    "# define the messages\n",
    "messages = [\n",
    "  SystemMessage(content=\"translate the following from english into chinese\"),\n",
    "  HumanMessage(content=\"hello!\")\n",
    "]\n",
    "\n",
    "# call llm\n",
    "result = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got it.\n",
    "```\n",
    "AIMessage(content='你好！', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 22, 'total_tokens': 25}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-a6ef502b-8b5d-4aab-8a5a-0678485e5d85-0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is an AIMessage object. Usually, we only need to extract the content property and display it to the user. \n",
    "\n",
    "Now let's extract the text content from the AIMessage object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `StrOutputParser`\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can modify the code to define a result variable to store the invocation result\n",
    "\n",
    "```python\n",
    "result = model.invoke(messages)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'你好!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
